{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), os.pardir)))\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "from ncamol.models.trainer.trainer import lightning_train_loop\n",
    "from ncamol.data_prep.voxel_tools.voxel import Voxel_Ligand\n",
    "from ncamol.visulization import plot_voxel\n",
    "from ncamol.models.utils import flush_cuda_cache\n",
    "from ncamol.models.model import LitModel\n",
    "\n",
    "from Bio import BiopythonWarning\n",
    "from Bio.PDB import PDBParser\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "warnings.simplefilter(\"ignore\", BiopythonWarning)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_protein_pdbs = \"../data/small_proteins/pdb/\"\n",
    "save_path = \"../data/small_proteins/voxelized/\"\n",
    "\n",
    "for path in [save_path, small_protein_pdbs]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def clear_all():\n",
    "    import gc\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "def prepare_inputs(\n",
    "    pockets: list[torch.tensor], n_hidden: int = 12\n",
    ") -> list[torch.tensor]:\n",
    "    inputs = torch.tensor([])\n",
    "\n",
    "    for pocket in pockets:\n",
    "        is_air = torch.max(pocket, dim=0)[0].unsqueeze(0)\n",
    "        n_hidden = n_hidden\n",
    "        hidden_channels = (is_air == 1).repeat(n_hidden, 1, 1, 1)\n",
    "\n",
    "        pocket = (\n",
    "            torch.cat(\n",
    "                [(is_air == 0), pocket, (is_air == 1), hidden_channels], dim=0\n",
    "            )\n",
    "            .unsqueeze(0)\n",
    "            .to(torch.float)\n",
    "        )\n",
    "        inputs = torch.cat([inputs, pocket], dim=0)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def load_inputs(path=\"../data/small_proteins/voxelized/\"):\n",
    "    inputs = []\n",
    "    files = os.listdir(path)\n",
    "    files.sort()\n",
    "    for file in files:\n",
    "        if file.endswith(\"input.npy\"):\n",
    "            inputs.append(torch.tensor(np.load(f\"{path}{file}\")[:3, ...]))\n",
    "    return inputs\n",
    "\n",
    "\n",
    "def load_targets(path=\"../data/small_proteins/voxelized/\"):\n",
    "    targets = []\n",
    "    files = os.listdir(path)\n",
    "    files.sort()\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith(\"target.npy\"):\n",
    "            targets.append(torch.tensor(np.load(f\"{path}{file}\")[:3, ...]))\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Protein backbone representation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDBs were preprocessed in PyMol e.g.:\n",
    " * fetch 1ahO\n",
    " * show sticks\n",
    " * remove solvent | not polymer | hydrogens | sidechain\n",
    " * (remove resi 33-37)\n",
    " * save PATH/TO/SAVE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins = [\"1aho\", \"1sp1\", \"3nir\"]\n",
    "protein_inputs = [\"1ahodel33_37\", \"1sp1del18_22\", \"3nirdel35_38\"]\n",
    "\n",
    "for protein, protein_input in zip(proteins, protein_inputs):\n",
    "    file = f\"{small_protein_pdbs}{protein}.pdb\"\n",
    "    parser = PDBParser()\n",
    "    structure = parser.get_structure(protein, file)[0]\n",
    "\n",
    "    v_t = Voxel_Ligand(\n",
    "        structure,\n",
    "        grid_size=40,\n",
    "        aggregation=\"surround\",\n",
    "    )\n",
    "\n",
    "    voxels = v_t._voxelize()\n",
    "    np.save(f\"{save_path}{protein}_target.npy\", voxels)\n",
    "\n",
    "    file = f\"{small_protein_pdbs}{protein_input}.pdb\"\n",
    "    parser = PDBParser()\n",
    "    structure = parser.get_structure(protein_input, file)[0]\n",
    "\n",
    "    v = Voxel_Ligand(\n",
    "        structure,\n",
    "        grid_size=40,\n",
    "        aggregation=\"surround\",\n",
    "        center_vector=v_t.center_vector\n",
    "    )\n",
    "\n",
    "    voxels = v._voxelize()\n",
    "    np.save(f\"{save_path}{protein}_input.npy\", voxels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_voxel(voxels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = load_inputs()\n",
    "targets = load_targets()\n",
    "prepared_inputs = prepare_inputs(inputs)\n",
    "prepared_targets = prepare_inputs(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_path = Path(\"../models/logs/backbone_recon/atom_channels/\")\n",
    "backbone_config = {\n",
    "    \"normal_std\": 0.01,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"alive_threshold\": 0.1,\n",
    "    \"cell_fire_rate\": 0.5,\n",
    "    \"steps\": [48, 64],\n",
    "    \"num_categories\": 4,\n",
    "    \"num_hidden_channels\": 12,\n",
    "    \"num_epochs\": 20000,\n",
    "    \"channel_dims\": [34, 34],\n",
    "    \"from_pocket\": False,\n",
    "    \"report_interval\": 50,\n",
    "    \"logging_path\": logging_path,\n",
    "}\n",
    "\n",
    "states, losses, model = lightning_train_loop(\n",
    "    x0=prepared_inputs, target=prepared_targets, **backbone_config\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
